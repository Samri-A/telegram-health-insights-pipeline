
#  Telegram Health Insights Pipeline

A production-grade data engineering pipeline for collecting, enriching, transforming, and serving insights from Ethiopian Telegram health-related channels. This project enables structured analysis of medical and cosmetic businesses operating through Telegram using modern data engineering tools like Docker, dbt, FastAPI, YOLOv8, and Dagster.

---

## ğŸ“Œ What It Does

This pipeline extracts public data from various Ethiopian Telegram channels, stores and transforms it into an analytical data warehouse, enriches it using object detection models, and provides accessible APIs for downstream reporting and insight generation.

---

## ğŸ”§ Tech Stack

- **Python 3.10+**
- **Docker & Docker Compose**
- **PostgreSQL**
- **dbt (Data Build Tool)**
- **YOLOv8 (Ultralytics)**
- **FastAPI + Uvicorn**
- **Dagster (Orchestration)**
- **Telethon (Telegram Scraping)**

---

## ğŸ§± Project Structure

```

telegram-health-pipeline/
â”œâ”€â”€ data/                      # Raw and processed data lake
â”‚   â””â”€â”€ raw/telegram\_messages/
â”œâ”€â”€ dbt/                      # dbt models for transformation
â”œâ”€â”€ fastapi\_app/              # FastAPI service
â”œâ”€â”€ telegram\_scraper/         # Telegram scraping logic
â”œâ”€â”€ yolo\_enrichment/          # YOLOv8 object detection scripts
â”œâ”€â”€ dagster\_pipeline/         # Dagster jobs and ops
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env                      # Secrets (excluded from git)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md

````

---

## âš™ï¸ Features

- ğŸ” **Telegram Data Collection**  
  Scrapes text and media (e.g., product images) from public Ethiopian medical/cosmetic channels using Telethon.

- ğŸ’¾ **Data Lake and Database**  
  Raw JSON data is saved to a structured local directory, then loaded into PostgreSQL for further transformation.

- ğŸ”„ **Data Transformation with dbt**  
  Implements a star schema (`fct_messages`, `dim_channels`, `dim_dates`) using staging and data mart models. Includes data quality testing and autogenerated documentation.

- ğŸ§  **Image Enrichment with YOLOv8**  
  Uses Ultralytics' YOLOv8 model to detect objects in product images. Detected objects are joined into the warehouse (`fct_image_detections`) via message IDs.

- ğŸŒ **API for Analytics**  
  FastAPI app exposes endpoints for querying top products, channel activity, and keyword-based searches from the final data models.

- ğŸ›  **Pipeline Orchestration**  
  Dagster powers a fully orchestrated pipeline with observable ops: scraping, loading, transformation, and enrichment â€” all schedulable and inspectable from the Dagster UI.

---

## ğŸ³ Quick Start (Docker)

Clone the repository:

```bash
git clone https://github.com/your-username/telegram-health-pipeline.git
cd telegram-health-pipeline
````

Create a `.env` file with the following format:

```env
TELEGRAM_API_ID=your_telegram_api_id
TELEGRAM_API_HASH=your_telegram_api_hash
POSTGRES_USER=postgres
POSTGRES_PASSWORD=postgres
POSTGRES_DB=telegram_data
DATABASE_URL=postgresql://postgres:postgres@db:5432/telegram_data
```

Run the stack:

```bash
docker-compose up --build
```

---

## ğŸ“¡ API Endpoints

```http
GET /api/reports/top-products?limit=10
GET /api/channels/{channel_name}/activity
GET /api/search/messages?query=paracetamol
```

These endpoints return aggregated results from the data warehouse, not just raw data.

---

## ğŸ§  How It Works

1. **Scraper** pulls messages/images from selected Telegram channels.
2. **Raw data** is saved in a JSON partitioned structure.
3. **Loader script** ingests JSON into PostgreSQL raw tables.
4. **dbt** transforms the data into analytical models with tests.
5. **YOLOv8 model** runs on scraped images to detect products or logos.
6. **Enrichment results** are saved as a new fact table.
7. **FastAPI** reads from the final data mart and exposes analytical APIs.
8. **Dagster orchestrator** schedules and monitors the entire pipeline.

---

## ğŸ§ª Testing and Validation

* dbtâ€™s built-in tests: `unique`, `not_null`
* Custom SQL tests for business rules (e.g., images must have a detection or tag)
* Logging for all scraping and enrichment tasks
* Unit tests for core FastAPI routes

---

## ğŸ›¡ Security Notes

* All credentials and API keys are managed via `.env` and loaded with `python-dotenv`
* `.env` is excluded from version control with `.gitignore`

---

## ğŸ“– Documentation

To generate dbt docs:

```bash
cd dbt/
dbt docs generate
dbt docs serve
```

Visit `http://localhost:8080` to browse documentation and lineage graphs.

---

## â± Scheduling

Use Dagster UI to schedule the end-to-end pipeline:

```bash
dagster dev
```

Visit `http://localhost:3000` to access the Dagster web UI and create schedules or trigger jobs.

---

## ğŸ§‘â€ğŸ’» Local Development

```bash
python -m venv env
source env/bin/activate  # or .\env\Scripts\activate on Windows
pip install -r requirements.txt
```

Run the API:

```bash
uvicorn fastapi_app.main:app --reload
```

